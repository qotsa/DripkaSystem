input {
  # aggregate containers logs via docker's gelf driver
  gelf {
    type => "raw"
    port => 12201

    # this would be ideal. unfortunately codecs does not work at all here
    #codec => multiline {
    #  pattern => "^%{TIMESTAMP_ISO8601}"
    #  negate => true
    #  what => "previous"
    #}
  }

  # aggregate applications logs via tcp, for example by logback's logstash appender
  tcp {
    type => "business"
    port => 4560
    codec => json_lines
  }
}

filter {
  if [type] == "raw" {
    multiline {
      pattern => "^%{TIMESTAMP_ISO8601}"
      negate => true
      what => "previous"
      source => "message"
      stream_identity => "%{host}.%{container_id}"
    }

    # extract fields from raw log data
    grok {
      match => {
        "message" => "^%{TIMESTAMP_ISO8601:[createdAt]} \[%{USERNAME:[thread]}]%{SPACE}%{NOTSPACE:[log_level]}%{SPACE}%{NOTSPACE:[logger_name]} - %{GREEDYDATA:[@metadata][message]}\n*$"
      }
    }

    mutate {
      replace => { "message" => "%{[@metadata][message]}"}
    }
  }

  if [type] == "business" {
    # parse log data depending on source app

    if [appName] == "smev3adapter" {
      # extract some fields from camel exchange
      kv {
        source => "message"
        include_keys => ["Direction", "operationName", "operationNamespace"]
        trim => "<>\[\],"
        trimkey => "<>\[\],"
      }
    }
  }

  de_dot {
  }
}

output {
  if [type] == "raw" {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "raw-%{+YYYY.MM.dd}"
    }
  }

  if [type] == "business" {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "business-%{+YYYY.MM.dd}"
    }
  }
}